================================================================================
ArXiv 计算机科学论文列表
生成时间: 2026-02-12 23:21:05
论文数量: 5
================================================================================

论文 1: Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling
------------------------------------------------------------
ID: 2602.11146v1
作者: Gongye Liu, Bo Yang, Yida Zhi, Zhizhou Zhong, Lei Ke, Didan Deng, Han Gao, Yongxiang Huang, Kaihao Zhang, Hongbo Fu, Wenhan Luo
发表时间: 2026-02-11 18:57:29
更新时间: 2026-02-11 18:57:29
主要分类: cs.CV
所有分类: cs.CV, cs.AI
PDF链接: https://arxiv.org/pdf/2602.11146v1
备注: Code: https://github.com/HKUST-C4G/diffusion-rm
摘要: Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerge...
相关链接:
  - https://arxiv.org/abs/2602.11146v1
  - https://arxiv.org/pdf/2602.11146v1

================================================================================

论文 2: GENIUS: Generative Fluid Intelligence Evaluation Suite
------------------------------------------------------------
ID: 2602.11144v1
作者: Ruichuan An, Sihan Yang, Ziyu Guo, Wei Dai, Zijun Shen, Haodong Li, Renrui Zhang, Xinyu Wei, Guopeng Li, Wenshan Wu, Wentao Zhang
发表时间: 2026-02-11 18:55:54
更新时间: 2026-02-11 18:55:54
主要分类: cs.LG
所有分类: cs.LG, cs.AI, cs.CV
PDF链接: https://arxiv.org/pdf/2602.11144v1
摘要: Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\textit{Crystallized Intelligence}$, which relies on recalling accu...
相关链接:
  - https://arxiv.org/abs/2602.11144v1
  - https://arxiv.org/pdf/2602.11144v1

================================================================================

论文 3: Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows
------------------------------------------------------------
ID: 2602.11142v1
作者: Shaswat Garg, Matin Moezzi, Brandon Da Silva
发表时间: 2026-02-11 18:54:48
更新时间: 2026-02-11 18:54:48
主要分类: cs.RO
所有分类: cs.RO, cs.AI, cs.LG
PDF链接: https://arxiv.org/pdf/2602.11142v1
备注: 9 pages, 3 figures, IEEE International Conference on Robotics and Automation 2026
摘要: Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practica...
相关链接:
  - https://arxiv.org/abs/2602.11142v1
  - https://arxiv.org/pdf/2602.11142v1

================================================================================

论文 4: Weight Decay Improves Language Model Plasticity
------------------------------------------------------------
ID: 2602.11137v1
作者: Tessa Han, Sebastian Bordt, Hanlin Zhang, Sham Kakade
发表时间: 2026-02-11 18:49:26
更新时间: 2026-02-11 18:49:26
主要分类: cs.LG
所有分类: cs.LG, cs.AI, cs.CL
PDF链接: https://arxiv.org/pdf/2602.11137v1
摘要: The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimiza...
相关链接:
  - https://arxiv.org/abs/2602.11137v1
  - https://arxiv.org/pdf/2602.11137v1

================================================================================

论文 5: FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight
------------------------------------------------------------
ID: 2602.11136v1
作者: Jiayi Zhou, Yang Sheng, Hantao Lou, Yaodong Yang, Jie Fu
发表时间: 2026-02-11 18:48:11
更新时间: 2026-02-11 18:48:11
主要分类: cs.AI
所有分类: cs.AI
PDF链接: https://arxiv.org/pdf/2602.11136v1
备注: 27 pages
摘要: As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces...
相关链接:
  - https://arxiv.org/abs/2602.11136v1
  - https://arxiv.org/pdf/2602.11136v1

================================================================================

